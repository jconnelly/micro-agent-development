groups:
  - name: micro-agent-alerts
    rules:
      # API Health Monitoring
      - alert: APIDown
        expr: up{job="micro-agent-api"} == 0
        for: 30s
        labels:
          severity: critical
          service: micro-agent-api
        annotations:
          summary: "Micro-Agent API is down"
          description: "The Micro-Agent API has been down for more than 30 seconds."
          
      - alert: HighErrorRate
        expr: rate(http_requests_total{status=~"5.."}[5m]) > 0.1
        for: 2m
        labels:
          severity: warning
          service: micro-agent-api
        annotations:
          summary: "High error rate detected"
          description: "API error rate is {{ $value | humanizePercentage }} which is above the 10% threshold."
          
      - alert: HighResponseTime
        expr: histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m])) > 2
        for: 5m
        labels:
          severity: warning
          service: micro-agent-api
        annotations:
          summary: "High response time"
          description: "95th percentile response time is {{ $value | humanizeDuration }} which exceeds 2 seconds."
          
      # Resource Monitoring  
      - alert: HighMemoryUsage
        expr: (process_resident_memory_bytes{job="micro-agent-api"} / (1024*1024*1024)) > 2
        for: 5m
        labels:
          severity: warning
          service: micro-agent-api
        annotations:
          summary: "High memory usage"
          description: "API memory usage is {{ $value | humanize }}GB which exceeds 2GB threshold."
          
      - alert: HighCPUUsage
        expr: rate(process_cpu_seconds_total{job="micro-agent-api"}[5m]) > 0.8
        for: 10m
        labels:
          severity: warning
          service: micro-agent-api
        annotations:
          summary: "High CPU usage"
          description: "API CPU usage is {{ $value | humanizePercentage }} which exceeds 80% threshold."
          
      # Redis Monitoring (when enabled)
      - alert: RedisDown
        expr: up{job="redis"} == 0
        for: 1m
        labels:
          severity: critical
          service: redis
        annotations:
          summary: "Redis cache is down"
          description: "Redis cache has been unavailable for more than 1 minute."
          
      - alert: RedisHighMemoryUsage
        expr: (redis_memory_used_bytes{job="redis"} / redis_config_maxmemory{job="redis"}) > 0.9
        for: 5m
        labels:
          severity: warning
          service: redis
        annotations:
          summary: "Redis high memory usage"
          description: "Redis memory usage is {{ $value | humanizePercentage }} which exceeds 90% of configured maximum."
          
      # Business Logic Monitoring
      - alert: PiiScrubbingFailures
        expr: rate(pii_scrubbing_failures_total[5m]) > 0.01
        for: 2m
        labels:
          severity: warning
          service: pii-agent
        annotations:
          summary: "PII scrubbing failures detected"
          description: "PII scrubbing failure rate is {{ $value | humanizePercentage }} which may indicate data protection issues."
          
      - alert: RuleExtractionTimeouts
        expr: rate(rule_extraction_timeouts_total[5m]) > 0.05
        for: 5m
        labels:
          severity: warning
          service: extraction-agent
        annotations:
          summary: "Rule extraction timeouts"
          description: "Rule extraction timeout rate is {{ $value | humanizePercentage }} which may indicate performance issues."

  # Prometheus Self-Monitoring
  - name: prometheus-alerts
    rules:
      - alert: PrometheusConfigReloadFailed
        expr: prometheus_config_last_reload_successful != 1
        for: 5m
        labels:
          severity: warning
          service: prometheus
        annotations:
          summary: "Prometheus configuration reload failed"
          description: "Prometheus configuration reload has failed. Configuration changes may not be active."
          
      - alert: PrometheusTSDBWalCorrupted
        expr: prometheus_tsdb_wal_corruptions_total > 0
        for: 1m
        labels:
          severity: critical
          service: prometheus
        annotations:
          summary: "Prometheus TSDB WAL corrupted" 
          description: "Prometheus TSDB write-ahead log is corrupted. Data loss may occur."